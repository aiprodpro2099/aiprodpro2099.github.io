[{"categories":["Self-Driving Cars"],"contents":"This is an introduction course to self-driving cars and Apollo platform - The Android of Self-Driving Car. Through this course, you will be able to identify key parts of self-driving cars and get to know Apollo architecture. You will be able to utilize Apollo HD Map, localization, perception, prediction, planning and control, and start the learning path of building a self-driving car.\nMy notes for this course:\n Lecture 1: SCD Fundamentals Lecture 2: HD Maps Lecture 3: Localization Lecture 4: Perception Lecture 5: Prediction Lecture 6: Planning Lecture 7: Control  ","permalink":"https://aiprodpro2099.github.io/posts/apollo-sdc-lessons-intro/","tags":["Computer Vision","Apollo"],"title":"[MOOC] Apollo Lessons on Self-Driving Cars"},{"categories":["Self-Driving Cars"],"contents":"This is my note for lesson 3 of MOOC course: Self-Driving Fundamentals - Featuring Apollo. Content: How the vehicle localizes itself with a single-digit-centimeter-level accuracy.\nLocalization methods in Apollo  The RTK (Real Time Kinematic) based method which incorporates GPS and IMU (Inertial Measurement Unit) information. The multi-sensor fusion method which incorporates GPS, IMU, and LiDAR information.  Inertial navigation Global Navigation Satellite System (GNSS) Global Navigation Satellite System (GNSS) refers to a constellation of satellites providing signals from space that transmit positioning and timing data to GNSS receivers. The receivers then use this data to determine location. Global Positioning System (GPS) is a kind of GNSS.\nProperties:\n Accurate with RTK Poor performance in urban area and canyons Low frequency update (~10Hz) ➝ Too slow for realtime positioning on SDC.  Inertial Measurement Unit (IMU) On Wikipedia: An inertial measurement unit (IMU) is an electronic device that measures and reports a body's specific force, angular rate, and sometimes the orientation of the body, using a combination of accelerometers, gyroscopes, and sometimes magnetometers.\nComponents of IMU:\n Accelerometer: measures velocity and acceleration Gyroscope: measures rotation and rotational rate Magnetometer: establishes cardinal direction (directional heading)  Disadvantage: The IMU's motion error increase with time.\nGPS + IMU We can combine GPS + IMU to localize the car. On one hand, IMU compensates for the low update frequency of GPS. On the other hand, GPS corrects the IMU's motion errors.\nLiDAR Localization With LiDAR, we can localize a car by means of point cloud matching. This method continuously matches the detected data from LiDAR sensors with the preexisting HD map. ➝ Require constantly updated HD map ➝ Very difficult.\nVisual localization Can we use images from cameras to localize the car?\nYes, but using only camera is hard. We often combine images with other sensor signals.\nParticle Filter: We use particles or points on the map to estimate our most likely location.\nApollo Localization Apollo localization using input from multiple sources and use Kalman Filter for sensor fusion.\nSensor fusion for localization\nKidnapped Vehicle TODO: Try Kidnapped Vehicle Project.\n","permalink":"https://aiprodpro2099.github.io/posts/apollo-sdc-lesson-3-localization/","tags":["Computer Vision","Apollo"],"title":"[MOOC] Apollo Lesson 3: Localization"},{"categories":["Self-Driving Cars"],"contents":"This is my note for lesson 2 of MOOC course: Self-Driving Fundamentals - Featuring Apollo. Content: High Definition maps for self driving cars.\nHD Maps have a high precision and contain a lot of information than your ordinary map on smartphone, such as lane line markings, 3D representation of the road network, traffic signs... You can what you see and GPS to locate your self in the world and identify other objects. However, it's very difficult with a self driving car, so we need HD Maps for current SDCs.\nHD Maps\nPrecision  Navigation map on your phone: meter-level precision HD Maps: centimeter-level precision  Localization on HD Maps Self-driving car uses sensor and camera signals to recognize where it is on HD Map.\nLocalization on HD Maps\nStandard  Apollo uses OpenDRIVE map format, and improve it to become Apollo OpenDRIVE standard.  Map construction  Steps for map production:  Map production\n","permalink":"https://aiprodpro2099.github.io/posts/apollo-sdc-lesson-2-hd-maps/","tags":["Computer Vision","Apollo"],"title":"[MOOC] Apollo Lesson 2: HD Maps"},{"categories":["Self-Driving Cars"],"contents":"This is my note for lesson 1 of MOOC course: Self-Driving Fundamentals - Featuring Apollo. Content: Identify the key parts of self-driving cars. The Apollo team and architecture.\nHuman vs Self-driving Car    Human Self-Driving Car     High traffic accident rate More reliable driving   Learn to drive from scratch Learnable driving system   Parking trouble No parking trouble    Six levels of self-driving car   Level 0: Base level - No autonomous task\n  Level 1: Driver assistance\n Driver Fully Engaged    Level 2: Partial Automation\n Automatic Cruise Control Automatic Lane Keeping    Level 3: Conditional Automation\n Human Take Over Whenever Necessary    Level 4: No Human Interference\n Without Steering Wheel, Throttle or Brake Restricted in Geofence    Level 5: Full Automation\n  Apollo platform 1. Hardware The hardware system of a self-driving car. Image from Apollo course\n  The Controller Area Network (CAN) cars is how the computer system connects to the car internal network to send signals for acceleration, braking and steering.\n  The Global Positioning System (GPS) receives signals from satellites, circling the earth. These signal help to determine our location.\n  The Inertial Measurement Unit (IMU) measure the vehicle movement and location by tracking the position, speed, acceleration and other factors.\n  LiDAR is an array of pulse layers. The LiDAR of Apollo can scan 360 degrees around the vehicle. The reflection of these lazer beams builds the point cloud that our software can use to understand the environment.\n  Cameras can be used to capture environment. For example because cameras can perceive color, they can be use to detect and understanding traffic lights.\n  Radar is also used for detecting obstacle. However, it's difficult to understand what kind of obstacle that radar has detected. Advantages: it's economical, it works in all weather and lighting condition.\n  2. Open Software Stack Sublayers:\n Real-time operating system (RTOS) Runtime framework Application modules  Real-time operating system (RTOS) Apollo RTOS\nApollo RTOS is a combination of Ubuntu linux and the Apollo kernel.\n Ubuntu is popular but not a RTOS. Ubuntu + Apollo kernel -\u0026gt; RTOS.  Runtime framework: Customized ROS (Robot Operation System) To adapt ROS for self-driving cars, the Apollo teams has:\n Improve functionality Improve performance for shared memory, decentralization and data comparability  Apollo uses shared memory\nShared memory pattern\nApollo decentralize ROS architecture\n The original architecture of ROS:  ROS Master fails\n Decentralized architecture of ROS:  Decentralized Architecture\nApollo used Protobuf instead of native ROS Message for data comparability between different versions of the system\n3 Apollo Cloud Service  HD Map Simulation Data platform Security OTA  Apollo Github Link to Github repo: https://github.com/ApolloAuto/apollo.\n","permalink":"https://aiprodpro2099.github.io/posts/apollo-sdc-lesson-1-fundamentals/","tags":["Computer Vision","Apollo"],"title":"[MOOC] Apollo Lesson 1: SDC Fundamentals"}]